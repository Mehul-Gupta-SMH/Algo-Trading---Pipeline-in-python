{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fb5612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1938b520",
   "metadata": {},
   "source": [
    "## Importing Selenium and Drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4800cde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "from selenium.webdriver.chrome.options import Options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231bd3bf",
   "metadata": {},
   "source": [
    "## Importing Data Processing Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a523cffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fbbf13",
   "metadata": {},
   "source": [
    "## Import User Defined Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8522b933",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod_utility import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f66b198",
   "metadata": {},
   "source": [
    "## Create User Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c18c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_fundamentals_table_data(my_list:list) -> list:\n",
    "    \"\"\"\n",
    "    \n",
    "    Clean Parsed table data for fundamentals\n",
    "    ------------------------------------\n",
    "    \n",
    "    Input:\n",
    "    my_list (list) : Table row to be cleaned\n",
    "    \n",
    "    ------------------------------------\n",
    "    Output:\n",
    "    my_list (list) : Cleaned Row\n",
    "    \n",
    "    \"\"\"    \n",
    "    \n",
    "    my_list = list(map(str.strip, my_list))\n",
    "    \n",
    "    strings_to_clean = ['' ,\n",
    "                        '        ' ,\n",
    "                        '          ']\n",
    "    \n",
    "    for string in strings_to_clean:\n",
    "        try:\n",
    "            while True:\n",
    "                my_list.remove(string)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    \n",
    "    \n",
    "    my_list = list(map(lambda x: x.replace(\",\",\"\"), my_list))\n",
    "    \n",
    "    my_list = list(map(lambda x: x.replace(\"+\",\"\"), my_list))\n",
    "    \n",
    "    return my_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c02cb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fundamentals_data_tables(bs4_soup_data_list , params_fndmntls_data:dict , pading_cols:dict):\n",
    "    \n",
    "    data_section_tag = params_fndmntls_data.get('data_section_tag','section')\n",
    "    data_section_tag_id = params_fndmntls_data.get('data_section_tag_id','id')\n",
    "    \n",
    "    table_section_tag = params_fndmntls_data.get('table_section_tag','table')\n",
    "    table_section_subtag = params_fndmntls_data.get('table_section_subtag','class')\n",
    "\n",
    "    parsed_table_df = pd.DataFrame()\n",
    "    \n",
    "    for tables in bs4_soup_data_list.findAll(data_section_tag):\n",
    "        \n",
    "        parsed_table_inter_df = pd.DataFrame()\n",
    "        \n",
    "        for table in tables.findAll(table_section_tag):\n",
    "            \n",
    "            print('\\t',tables.get(data_section_tag_id,''),\" -> \",'Data Parsing - Started')\n",
    "            \n",
    "            rows = []\n",
    "            header = []\n",
    "            values = []\n",
    "\n",
    "            for row in table.findAll(\"tr\"):\n",
    "                values.append(row.text.split(\"\\n\"))\n",
    "            \n",
    "            values = list(map(clean_fundamentals_table_data,values))\n",
    "            \n",
    "            header = ['Metric'] + values[0]\n",
    "\n",
    "            rows = values[1:]\n",
    "\n",
    "            try:\n",
    "                parsed_table_inter_df = pd.DataFrame(rows,columns=header)\n",
    "                \n",
    "                parsed_table_inter_df = pd.melt(\n",
    "                        parsed_table_inter_df, \n",
    "                        id_vars =list(parsed_table_inter_df.columns)[0], \n",
    "                        value_vars =list(parsed_table_inter_df.columns)[1:]\n",
    "                       )\n",
    "\n",
    "                parsed_table_inter_df['fundamental_data_type'] = tables.get(data_section_tag_id,'')\n",
    "                \n",
    "                \n",
    "                if parsed_table_df.shape[0]:\n",
    "                    parsed_table_df = pd.concat(parsed_table_inter_df,parsed_table_df)\n",
    "                else:\n",
    "                    parsed_table_df = parsed_table_inter_df\n",
    "                \n",
    "                print('\\r\\t',tables.get(data_section_tag_id,''),\" -> \",'Data Parsing - Success\\n')\n",
    "                \n",
    "            except:\n",
    "                print('\\r\\t',tables.get(data_section_tag_id,''),\" -> \",'Data Parsing - Failed\\n')\n",
    "    \n",
    "    parsed_table_df[list(pading_cols.keys())] = list(pading_cols.values())\n",
    "    \n",
    "    return parsed_table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2941eb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fundamentals_data_wrapper(extracted_url_df):\n",
    "    \"\"\"\n",
    "    \n",
    "    Get Funadamentals data for the identified ticker \n",
    "    ------------------------------------\n",
    "    \n",
    "    Input:\n",
    "    params_fundamentals (dict) : parameter for scraping fundamentals data \n",
    "    params_iter (dict) : Dictionary of parameters that are required to iterate over the web page\n",
    "    \n",
    "    ------------------------------------\n",
    "    Output:\n",
    "    \n",
    "    \"\"\"    \n",
    "    \n",
    "    fundamentals_data_df = pd.DataFrame()\n",
    "    \n",
    "    for index,stocks in extracted_url_df.iterrows():\n",
    "        \n",
    "        print('Fundamantals Data -> ',stocks['Org Name'],'(',stocks['ticker_cd'],')\\n')\n",
    "    \n",
    "        url = \"https://www.screener.in/company/{}/consolidated/#profit-loss\".format(stocks['ticker_cd'])\n",
    "\n",
    "        driver_data = get_driver_data(url , params_iter)\n",
    "\n",
    "        page_content_str = driver_data.page_source\n",
    "        bs4_soup_data_list = BeautifulSoup(page_content_str)\n",
    "        \n",
    "        driver_data.close()\n",
    "\n",
    "        params_fndmntls_data = {\n",
    "            'data_section_tag':'section' ,\n",
    "            'data_section_tag_id':'id' ,\n",
    "            'table_section_tag':'table' ,\n",
    "            'table_section_subtag':'class' ,\n",
    "        }\n",
    "\n",
    "        pading_cols = {\n",
    "            \"ticker_cd\" : stocks['ticker_cd'],\n",
    "            \"Org Name\" : stocks['Org Name']\n",
    "        }\n",
    "\n",
    "        inter_fundamentals_data_df = pd.DataFrame()\n",
    "        inter_fundamentals_data_df = get_fundamentals_data_tables(bs4_soup_data_list,params_fndmntls_data,pading_cols)\n",
    "        \n",
    "        if not inter_fundamentals_data_df.shape[0]:\n",
    "            pass\n",
    "        elif fundamentals_data_df.shape[0]:\n",
    "            fundamentals_data_df = pd.concat([inter_fundamentals_data_df,fundamentals_data_df])\n",
    "        else:\n",
    "            fundamentals_data_df = inter_fundamentals_data_df\n",
    "            \n",
    "    fundamentals_data_df = fundamentals_data_df.dropna().reset_index()\n",
    "    \n",
    "    fundamentals_data_df.drop(['index'],axis=1,inplace=True)\n",
    "    \n",
    "    return fundamentals_data_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
