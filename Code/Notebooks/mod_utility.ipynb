{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4654c3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "## Importing Selenium and Drivers\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c6d8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_driver_data(url:str,params_iter : dict):\n",
    "    \"\"\"\n",
    "    \n",
    "    Get the html data for the page opened by Selenium driver\n",
    "    ------------------------------------\n",
    "    \n",
    "    Input:\n",
    "    url (str) : url from which data is to be parsed \n",
    "    params_iter (dict) : Dictionary of parameters that are required to iterate over the web page\n",
    "    \n",
    "    ------------------------------------\n",
    "    Output:\n",
    "    Selenium.webdriver.Chrome object : Contains data about the page that needs to be parsed \n",
    "    \n",
    "    \"\"\"    \n",
    "    \n",
    "    SCROLL_PAUSE_TIME = params_iter['scroll_wait_time']\n",
    "    \n",
    "    options = Options()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--disable-gpu')\n",
    "    \n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()),options=options)\n",
    "    \n",
    "#     driver.minimize_window()\n",
    "    \n",
    "    ## Check if the URL has correct format\n",
    "    if not url_validator(url):\n",
    "        raise ValueError(\"The URL \"&url&\" is not a valid URL format\")\n",
    "        pass\n",
    "    \n",
    "    driver.get(url)\n",
    "    \n",
    "    ## Check what was the last height of the page\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    ## Get the whole page data by loading all data from lazy loading page\n",
    "    iteration = 0\n",
    "    while True:\n",
    "        \n",
    "        iteration += 1\n",
    "        \n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    \n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "        \n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        \n",
    "        if (new_height == last_height) or (iteration == params_iter['iter_threshold']):\n",
    "            break\n",
    "            \n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e29ed32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_validator(url:str) -> bool:\n",
    "    \"\"\"\n",
    "    \n",
    "    Validates if the url have correct format\n",
    "    ------------------------------------\n",
    "    \n",
    "    Input:\n",
    "    url (str) : url string to be checked \n",
    "    \n",
    "    ------------------------------------\n",
    "    Output:\n",
    "    Bool \n",
    "    \n",
    "    \"\"\"\n",
    "    regex = re.compile(\n",
    "            r'^(?:http|ftp)s?://' # http:// or https://\n",
    "            r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+(?:[A-Z]{2,6}\\.?|[A-Z0-9-]{2,}\\.?)|' #domain...\n",
    "            r'localhost|' #localhost...\n",
    "            r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})' # ...or ip\n",
    "            r'(?::\\d+)?' # optional port\n",
    "            r'(?:/?|[/?]\\S+)$', re.IGNORECASE)\n",
    "    \n",
    "    if re.match(regex, url):\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def get_industry_info(ticker,trial=0):\n",
    "    \n",
    "    if trial > 3:\n",
    "        print('Failed for ticker => ',ticker)\n",
    "        return ['','','','']\n",
    "    \n",
    "    if (ticker is None) or (ticker.strip() == ''):\n",
    "        return ['','','','']\n",
    "    \n",
    "    industry_data_df = pd.read_csv('industry.csv')\n",
    "    \n",
    "    filtered_industry_data_df = industry_data_df[industry_data_df['ticker']==ticker]\n",
    "    \n",
    "    if filtered_industry_data_df.shape[0]>0:\n",
    "        return [\n",
    "            filtered_industry_data_df['Macro-Economic Sector'].iat[0],\n",
    "            filtered_industry_data_df['Sector'].iat[0],\n",
    "            filtered_industry_data_df['Industry'].iat[0],\n",
    "            filtered_industry_data_df['Basic Industry'].iat[0]\n",
    "        ]\n",
    "    \n",
    "    else:\n",
    "        print(ticker)\n",
    "        \n",
    "        url = 'https://www.nseindia.com/get-quotes/equity?symbol={}'.format(ticker)\n",
    "\n",
    "        params_iter = {}\n",
    "        params_iter['scroll_wait_time'] = 5.0\n",
    "        params_iter['iter_threshold'] = 1\n",
    "\n",
    "        driver_data = get_driver_data(url , params_iter)\n",
    "\n",
    "        page_content_str = driver_data.page_source\n",
    "        bs4_soup_data_list = BeautifulSoup(page_content_str)\n",
    "\n",
    "        driver_data.close()\n",
    "\n",
    "        for table in bs4_soup_data_list.findAll('table'):\n",
    "            if table.attrs.get('id','') == 'industryInfo':\n",
    "                header = list(table.stripped_strings)[:4]\n",
    "                body = list(table.stripped_strings)[4:]\n",
    "                \n",
    "                try:\n",
    "                    industry_data_df.loc[len(industry_data_df)] = [ticker,'NSE',body[0],body[1],body[2],body[3]] \n",
    "\n",
    "                    industry_data_df.to_csv('industry.csv',index=False)\n",
    "                except:\n",
    "                    trial += 1\n",
    "                    return get_industry_info(ticker,trial)\n",
    "                \n",
    "                return body\n",
    "            \n",
    "        return ['','','','']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60db5e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_historical_data(symbol,start_date,end_date):\n",
    "    \n",
    "    payload_df = pd.DataFrame()\n",
    "    baseurl = \"https://www.nseindia.com/\"\n",
    "    series = \"EQ\"\n",
    "    headers = {\n",
    "        'Connection': 'keep-alive',\n",
    "        'Cache-Control': 'max-age=0',\n",
    "        'DNT': '1',\n",
    "        'Upgrade-Insecure-Requests': '1',\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.79 Safari/537.36',\n",
    "        'Sec-Fetch-User': '?1',\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "        'Sec-Fetch-Site': 'none',\n",
    "        'Sec-Fetch-Mode': 'navigate',\n",
    "        'Accept-Encoding': 'gzip, deflate, br',\n",
    "        'Accept-Language': 'en-US,en;q=0.9,hi;q=0.8',\n",
    "    }\n",
    "    \n",
    "    \n",
    "    dt_start_date = datetime.datetime.strptime(start_date,\"%d-%m-%Y\")\n",
    "    dt_end_date = datetime.datetime.strptime(end_date,\"%d-%m-%Y\")\n",
    "    \n",
    "    dt_inter_end_date = dt_start_date\n",
    "    \n",
    "    while (dt_end_date - dt_inter_end_date).days > 0:\n",
    "        \n",
    "        print(\"\\r\",dt_start_date,\" to \" , dt_inter_end_date , \" with days \" ,abs((dt_inter_end_date - dt_start_date).days))\n",
    "        \n",
    "        dt_inter_end_date = dt_inter_end_date + datetime.timedelta(days=40)\n",
    "        dt_inter_end_date = min([dt_inter_end_date,dt_end_date])\n",
    "        \n",
    "        inter_end_date = datetime.datetime.strftime(dt_inter_end_date,\"%d-%m-%Y\")\n",
    "        \n",
    "        url=\"https://www.nseindia.com/api/historical/cm/equity?symbol=\"+symbol+\"&series=[%22\"+series+\"%22]&from=\"+str(start_date)+\"&to=\"+str(inter_end_date)+\"\"\n",
    "    \n",
    "        session = requests.Session()\n",
    "        request = session.get(baseurl, headers=headers, timeout=5)\n",
    "        cookies = dict(request.cookies)\n",
    "        payload = session.get(url, headers=headers, timeout=5, cookies=cookies).json()\n",
    "\n",
    "        inter_payload_df = pd.DataFrame(payload['data'])\n",
    "        \n",
    "        if payload_df.shape[0]:\n",
    "            payload_df = pd.concat([payload_df,inter_payload_df])\n",
    "        else:\n",
    "            payload_df = inter_payload_df\n",
    "        \n",
    "    return payload_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
